{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import pandas as pd\n",
    "\n",
    "from astropy import stats\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and make some subsets for each wfs for inspection later\n",
    "dfs = []\n",
    "for y in [2017, 2018, 2019]:\n",
    "    dfs.append(pd.read_csv(f\"../raw_data/{y}_wfs.csv\"))\n",
    "data = pd.concat(dfs)\n",
    "data['ut'] = pd.to_datetime(data.ut)\n",
    "data['az'][data['az'] < 0.] += 360.\n",
    "\n",
    "f9 = data[data['wfs'] == 'newf9']\n",
    "f5 = data[data['wfs'] == 'f5']\n",
    "mmirs = data[data['wfs'] == 'mmirs']\n",
    "bino = data[data['wfs'] == 'binospec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrangle the times to add colums for mjd to look for trends over time and hour to look for nightly trends\n",
    "raw_times = data['time']\n",
    "times = Time(raw_times.values.tolist(), format='isot', scale='utc')\n",
    "mjd = times.mjd\n",
    "data['mjd'] = mjd.tolist()\n",
    "data['hour'] = data['ut'].dt.hour\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_series_2019 = pd.read_csv(\"../halcoll/data/halcoll_temps.csv\")\n",
    "e_series_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = data.drop(columns=['ut']).set_index(pd.DatetimeIndex(data['time'], name='ut'))\n",
    "fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_series = e_series_2019.set_index(pd.DatetimeIndex(e_series_2019['ts'], name='ut').tz_localize('MST').tz_convert(None)).drop(columns=['ts'])\n",
    "e_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge_asof(fixed.sort_index(), e_series, on='ut')\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim out columns not relevant to training\n",
    "trimmed = merged.drop(columns=['ut', 'time', 'airmass', 'cc_x_err', 'cc_y_err', 'chamt', 'osst', 'outt', 'exptime', 'file', 'focerr', 'fwhm', 'raw_seeing', 'residual_rms', 'seeing', 'wavefront_rms', 'xcen', 'ycen', 'comaerr'])\n",
    "trimmed = trimmed.dropna()\n",
    "trimmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['focus', 'tiltx', 'tilty', 'transx', 'transy']\n",
    "\n",
    "# assign columns for each wfs so we can use them as features for training\n",
    "wfs = trimmed.pop('wfs')\n",
    "trimmed['f9'] = (wfs == 'newf9') * 1\n",
    "trimmed['f5'] = (wfs == 'f5') * 1\n",
    "trimmed['mmirs'] = (wfs == 'mmirs') * 1\n",
    "trimmed['bino'] = (wfs == 'binospec') * 1\n",
    "trimmed = trimmed[(trimmed['hour'] > 0) & (trimmed['hour'] <= 13)]\n",
    "trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the large range in offsets is messing up the training. so normalize the hexapod coords to their means\n",
    "means = {}\n",
    "for w in ['f5', 'f9', 'mmirs', 'bino']:\n",
    "    means[w] = {}\n",
    "for l in labels:\n",
    "    # f/5 and bino are optically the same and have very similar mean hexapod coords\n",
    "    means['f5'][l] = trimmed[(trimmed['f5'] == 1) | (trimmed['bino'] == 1)][l].mean()\n",
    "    means['bino'][l] = means['f5'][l]\n",
    "    means['mmirs'][l] = trimmed[trimmed['mmirs'] == 1][l].mean()\n",
    "    means['f9'][l] = trimmed[trimmed['f9'] == 1][l].mean()\n",
    "\n",
    "for k in means:\n",
    "    for l in labels:\n",
    "        trimmed[l][trimmed[k] == 1] -= means[k][l]\n",
    "trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = trimmed.sample(frac=0.8, random_state=0)\n",
    "test_dataset = trimmed.drop(train_dataset.index)\n",
    "\n",
    "train_stats = train_dataset.describe()\n",
    "train_stats = train_stats.drop(columns=labels)\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = {}\n",
    "test_labels = {}\n",
    "for l in labels:\n",
    "    train_labels[l] = train_dataset.pop(l)\n",
    "    test_labels[l] = test_dataset.pop(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(32, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n",
    "        layers.Dense(128, activation=tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mean_absolute_error', 'mean_squared_error']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for l in labels:\n",
    "    models[l] = build_model()\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['focus'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: \n",
    "            print('')\n",
    "        print('.', end='')\n",
    "\n",
    "EPOCHS = 8000\n",
    "\n",
    "histories = {}\n",
    "\n",
    "for l in labels:\n",
    "    print(f\"Training {l} model....\")\n",
    "    histories[l] = models[l].fit(\n",
    "        normed_train_data, train_labels[l],\n",
    "        epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "        callbacks=[early_stop, PrintDot()]\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in labels:\n",
    "    models[l].save(f\"../halcoll/data/{l}_alldata_32x128_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, label=None):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    if label is not None:\n",
    "        plt.title(label)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    if label is not None:\n",
    "        plt.title(label)\n",
    "    plt.savefig(f\"{label}_train.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(histories['focus'], label=\"focus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(label):\n",
    "    loss, mae, mse = models[label].evaluate(normed_test_data, test_labels[label], verbose=0)\n",
    "\n",
    "    print(\"Testing set Mean Abs Error: {:5.2f} um\".format(mae))\n",
    "    print(\"Testing set RMS: {:5.2f} um\".format(np.sqrt(mse)))\n",
    "\n",
    "    test_predictions = models[label].predict(normed_test_data).flatten()\n",
    "\n",
    "    plt.scatter(test_labels[label], test_labels[label] - test_predictions)\n",
    "    plt.xlabel('True Values [um]')\n",
    "    plt.ylabel('Residuals [um]')\n",
    "    minx, maxx = min(test_labels[label]), max(test_labels[label])\n",
    "    plt.plot([minx, maxx], [0, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results('focus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = 'focus'\n",
    "test_predictions = models[lab].predict(normed_test_data).flatten()\n",
    "diff = test_labels[lab] - test_predictions\n",
    "diff.idxmax(), diff.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.loc[5986]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_data = normed_test_data[normed_test_data['f9'] > 0]\n",
    "#chk.index\n",
    "chk_test = test_labels['focus'][chk_data.index] \n",
    "chk_pred = models['focus'].predict(chk_data).flatten()\n",
    "chk_diff = chk_test - chk_pred\n",
    "chk_diff.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.loc[3125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = keras.models.load_model(\"/Users/tim/MMT/HALcoll/halcoll/data/tiltx_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(normed_test_data, test_labels['tiltx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = train_dataset['cell_e_series_chamber_ambient_C'] - train_dataset['yankee_temperature']\n",
    "ttt.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = models['focus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
