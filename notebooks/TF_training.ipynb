{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import pandas as pd\n",
    "\n",
    "from astropy import stats\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    log_device_placement=True\n",
    ")\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# load data and make some subsets for each wfs for inspection later\n",
    "dfs = []\n",
    "for y in [\"2018_2019\"]:\n",
    "    dfs.append(pd.read_csv(f\"../raw_data/{y}_wfs_loose.csv\"))\n",
    "data = pd.concat(dfs)\n",
    "data['ut'] = pd.to_datetime(data.ut)\n",
    "data['az'][data['az'] < 0.] += 360.\n",
    "\n",
    "f9 = data[(data['wfs'] == 'newf9') | (data['wfs'] == 'oldf9')]\n",
    "f5 = data[data['wfs'] == 'f5']\n",
    "mmirs = data[data['wfs'] == 'mmirs']\n",
    "bino = data[data['wfs'] == 'binospec']\n",
    "\n",
    "# wrangle the times to add colums for mjd to look for trends over time and hour to look for nightly trends\n",
    "raw_times = data['time']\n",
    "times = Time(raw_times.values.tolist(), format='isot', scale='utc')\n",
    "mjd = times.mjd\n",
    "data['mjd'] = mjd.tolist()\n",
    "data['hour'] = data['ut'].dt.hour\n",
    "\n",
    "e_series = pd.read_csv(\"../halcoll/data/halcoll_temps.csv\")\n",
    "\n",
    "fixed = data.drop(columns=['ut']).set_index(pd.DatetimeIndex(data['time'], name='ut'))\n",
    "\n",
    "e_series = e_series.set_index(pd.DatetimeIndex(e_series['ts'], name='ut').tz_localize('MST').tz_convert(None)).drop(columns=['ts'])\n",
    "\n",
    "merged = pd.merge_asof(fixed.sort_index(), e_series, on='ut')\n",
    "\n",
    "# trim out columns not relevant to training\n",
    "dropped_cols = [\n",
    "    'ut', 'time', 'airmass', 'cc_x_err', 'cc_y_err', 'chamt', 'osst',\n",
    "    'outt', 'exptime', 'file', 'focerr', 'fwhm', 'raw_seeing', 'residual_rms',\n",
    "    'seeing', 'wavefront_rms', 'xcen', 'ycen', 'comaerr'\n",
    "]\n",
    "trimmed = merged.drop(columns=dropped_cols)\n",
    "trimmed = trimmed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def norm(x, s):\n",
    "    return (x - s['mean']) / s['std']\n",
    "\n",
    "labels = ['focus', 'tiltx', 'tilty', 'transx', 'transy']\n",
    "\n",
    "# split data set up into three training sets: f9, mmirs, and f5/bino. these sets correspond to the three optical configurations\n",
    "# we use: f/9 and no corrector, f/5 with no corrector (mmirs), and f/5 with spectroscopic corrector (f5/bino).\n",
    "datasets = {}\n",
    "wfs = trimmed.pop('wfs')\n",
    "datasets['f9'] = trimmed[wfs == 'newf9']\n",
    "datasets['mmirs'] = trimmed[wfs == 'mmirs']\n",
    "datasets['f5'] = trimmed[(wfs == 'f5') | (wfs == 'binospec')]\n",
    "\n",
    "# the large range in offsets is messing up the training. so normalize the hexapod coords to their means\n",
    "means = {}\n",
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "train_labels = {}\n",
    "test_labels = {}\n",
    "train_stats = {}\n",
    "normed_train_data = {}\n",
    "normed_test_data = {}\n",
    "for w in datasets:\n",
    "    means[w] = {}\n",
    "    for l in labels:\n",
    "        means[w][l] = datasets[w][l].mean()\n",
    "        datasets[w][l] -= means[w][l]\n",
    "\n",
    "    train_datasets[w] = datasets[w].sample(frac=0.8, random_state=0)\n",
    "    test_datasets[w] = datasets[w].drop(train_datasets[w].index)\n",
    "    train_stats[w] = train_datasets[w].describe()\n",
    "    train_stats[w] = train_stats[w].drop(columns=labels)\n",
    "    train_stats[w] = train_stats[w].transpose()\n",
    "    \n",
    "    train_labels[w] = {}\n",
    "    test_labels[w] = {}\n",
    "    for l in labels:\n",
    "        train_labels[w][l] = train_datasets[w].pop(l)\n",
    "        test_labels[w][l] = test_datasets[w].pop(l)\n",
    "        \n",
    "    normed_train_data[w] = norm(train_datasets[w], train_stats[w])\n",
    "    normed_test_data[w] = norm(test_datasets[w], train_stats[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width=32, shape=1, nlayers=1, tolerance=0.001):\n",
    "    nn_layers = [layers.Dense(width, activation=tf.nn.relu, input_shape=[shape])]  # input_shape=[len(train_dataset.keys())])]\n",
    "\n",
    "    if nlayers > 0:\n",
    "        for i in range(nlayers-1):\n",
    "            nn_layers.append(layers.Dense(width, activation=tf.nn.relu))\n",
    "    \n",
    "    nn_layers.append(layers.Dense(1))\n",
    "    model = keras.Sequential(nn_layers)\n",
    "    optimizer = tf.keras.optimizers.RMSprop(tolerance)\n",
    "\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mean_absolute_error', 'mean_squared_error']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0921 16:05:45.584440 139852920898944 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "mod_config = {\n",
    "    \"f9\": {\n",
    "        'width': 8,\n",
    "        'nlayers': 3\n",
    "    },\n",
    "    \"f5\": {\n",
    "        'width': 64,\n",
    "        'nlayers': 2\n",
    "    },\n",
    "    'mmirs': {\n",
    "        'width': 64,\n",
    "        'nlayers': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "for w in datasets:\n",
    "    models[w] = {}\n",
    "    for l in labels:\n",
    "        models[w][l] = build_model(\n",
    "            width=mod_config[w]['width'],\n",
    "            shape=len(train_datasets[w].keys()),\n",
    "            nlayers=mod_config[w]['nlayers']\n",
    "        )\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 64)                1280      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,505\n",
      "Trainable params: 5,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models['mmirs']['focus'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training focus model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "........................\n",
      "\n",
      "Training tiltx model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..............................................\n",
      "\n",
      "Training tilty model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...........................................\n",
      "\n",
      "Training transx model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "........................................................................................\n",
      "\n",
      "Training transy model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...................................................................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: \n",
    "            print('')\n",
    "        print('.', end='')\n",
    "\n",
    "EPOCHS = 4000\n",
    "\n",
    "histories = {}\n",
    "\n",
    "for l in labels:\n",
    "    print(f\"Training {l} model....\")\n",
    "    histories[l] = models['mmirs'][l].fit(\n",
    "        normed_train_data['mmirs'], train_labels['mmirs'][l],\n",
    "        epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "        callbacks=[early_stop, PrintDot()]\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in labels:\n",
    "    models['f9'][l].save(f\"../halcoll/data/mmirs_{l}_2018_2019_loose_64x64_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, label=None):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    if label is not None:\n",
    "        plt.title(label)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    if label is not None:\n",
    "        plt.title(label)\n",
    "    plt.savefig(f\"{label}_train.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54994f2f74f84531a74a6a2bbcb7bda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdde7ba9ece41e99e13151d53cea02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(histories['focus'], label=\"focus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(wfs, label):\n",
    "    loss, mae, mse = models[wfs][label].evaluate(normed_test_data[wfs], test_labels[wfs][label], verbose=0)\n",
    "\n",
    "    print(\"Testing set Mean Abs Error: {:5.2f} um\".format(mae))\n",
    "    print(\"Testing set RMS: {:5.2f} um\".format(np.sqrt(mse)))\n",
    "\n",
    "    test_predictions = models[wfs][label].predict(normed_test_data[wfs]).flatten()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(test_labels[wfs][label], test_labels[wfs][label] - test_predictions)\n",
    "    plt.xlabel('True Values [um]')\n",
    "    plt.ylabel('Residuals [um]')\n",
    "    minx, maxx = min(test_labels[wfs][label]), max(test_labels[wfs][label])\n",
    "    plt.plot([minx, maxx], [0, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error: 12.03 um\n",
      "Testing set RMS: 18.48 um\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79a4ab600bc4fceb1d76f0e7ff07f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results('mmirs', 'focus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18649, 5502)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = 'focus'\n",
    "test_predictions = models['f9'][lab].predict(normed_test_data['f9']).flatten()\n",
    "diff = test_labels['f9'][lab] - test_predictions\n",
    "diff.idxmax(), diff.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[lab].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "az                                       254.111081\n",
       "el                                        65.569023\n",
       "mjd                                    58301.277643\n",
       "hour                                       6.000000\n",
       "cell_e_series_backplate_C                 11.031100\n",
       "cell_e_series_chamber_ambient_C           14.983700\n",
       "cell_e_series_frontplate_C                11.477500\n",
       "cell_e_series_in_front_of_primary_C       12.907900\n",
       "cell_e_series_lower_plenum_C              10.618600\n",
       "cell_e_series_midplate_C                  10.949900\n",
       "cell_e_series_outside_ambient_C           15.325400\n",
       "yankee_temperature                        15.146000\n",
       "temptrax1_probe2                          14.800000\n",
       "temptrax1_probe3                          15.200000\n",
       "temptrax1_probe4                          15.200000\n",
       "temptrax1_probe6                          14.700000\n",
       "temptrax3_probe10                         15.200000\n",
       "temptrax3_probe11                         15.400000\n",
       "temptrax3_probe12                         15.200000\n",
       "Name: 5502, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets['f9'].loc[5502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_data = normed_test_data[normed_test_data['f9'] > 0]\n",
    "#chk.index\n",
    "chk_test = test_labels['focus'][chk_data.index] \n",
    "chk_pred = models['focus'].predict(chk_data).flatten()\n",
    "chk_diff = chk_test - chk_pred\n",
    "chk_diff.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.loc[3125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = keras.models.load_model(\"/Users/tim/MMT/HALcoll/halcoll/data/tiltx_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(normed_test_data, test_labels['tiltx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = train_dataset['cell_e_series_chamber_ambient_C'] - train_dataset['yankee_temperature']\n",
    "ttt.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = models['focus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['focus', 'tiltx', 'tilty', 'transx', 'transy'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels['f9'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
