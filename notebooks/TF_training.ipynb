{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import pandas as pd\n",
    "\n",
    "from astropy import stats\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=8,\n",
    "    inter_op_parallelism_threads=8,\n",
    "    log_device_placement=True\n",
    ")\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, label=None):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    if label is not None:\n",
    "        plt.title(label)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "           label = 'Val Error')\n",
    "    plt.legend()\n",
    "    if label is not None:\n",
    "        plt.title(label)\n",
    "    plt.savefig(f\"{label}_train.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def build_model(width=32, shape=1, nlayers=1, tolerance=0.001):\n",
    "    nn_layers = [layers.Dense(width, activation=tf.nn.relu, input_shape=[shape])]  # input_shape=[len(train_dataset.keys())])]\n",
    "\n",
    "    if nlayers > 0:\n",
    "        for i in range(nlayers-1):\n",
    "            nn_layers.append(layers.Dense(width, activation=tf.nn.relu))\n",
    "    \n",
    "    nn_layers.append(layers.Dense(1))\n",
    "    model = keras.Sequential(nn_layers)\n",
    "    optimizer = tf.keras.optimizers.RMSprop(tolerance)\n",
    "\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mean_absolute_error', 'mean_squared_error']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def load_wfs_data(files=[f\"../raw_data/2018_2019_wfs_loose.csv\"]):\n",
    "    # load data and make some subsets for each wfs for inspection later\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        dfs.append(pd.read_csv(f))\n",
    "    data = pd.concat(dfs)\n",
    "    data['ut'] = pd.to_datetime(data.ut)\n",
    "    data['az'][data['az'] < 0.] += 360.\n",
    "\n",
    "    f9 = data[(data['wfs'] == 'newf9') | (data['wfs'] == 'oldf9')]\n",
    "    f5 = data[data['wfs'] == 'f5']\n",
    "    mmirs = data[data['wfs'] == 'mmirs']\n",
    "    bino = data[data['wfs'] == 'binospec']\n",
    "\n",
    "    # wrangle the times to add colums for mjd to look for trends over time and hour to look for nightly trends\n",
    "    raw_times = data['time']\n",
    "    times = Time(raw_times.values.tolist(), format='isot', scale='utc')\n",
    "    mjd = times.mjd\n",
    "    data['mjd'] = mjd.tolist()\n",
    "    data['hour'] = data['ut'].dt.hour\n",
    "\n",
    "    e_series = pd.read_csv(\"../halcoll/data/halcoll_temps.csv\")\n",
    "\n",
    "    fixed = data.drop(columns=['ut']).set_index(pd.DatetimeIndex(data['time'], name='ut'))\n",
    "\n",
    "    e_series = e_series.set_index(pd.DatetimeIndex(e_series['ts'], name='ut').tz_localize('MST').tz_convert(None)).drop(columns=['ts'])\n",
    "\n",
    "    merged = pd.merge_asof(fixed.sort_index(), e_series, on='ut')\n",
    "\n",
    "    # trim out columns not relevant to training\n",
    "    dropped_cols = [\n",
    "        'ut', 'time', 'airmass', 'cc_x_err', 'cc_y_err', 'chamt', 'osst',\n",
    "        'outt', 'exptime', 'file', 'focerr', 'fwhm', 'raw_seeing', 'residual_rms',\n",
    "        'seeing', 'wavefront_rms', 'xcen', 'ycen', 'comaerr'\n",
    "    ]\n",
    "    trimmed = merged.drop(columns=dropped_cols)\n",
    "    trimmed = trimmed.dropna()\n",
    "    return trimmed\n",
    "\n",
    "def norm_dataset(x, s):\n",
    "    return (x - s['mean']) / s['std']\n",
    "\n",
    "def unnorm_dataset(x, s):\n",
    "    return x * s['std'] + s['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "labels = ['focus', 'tiltx', 'tilty', 'transx', 'transy']\n",
    "trimmed = load_wfs_data(files=[\"../raw_data/2017_wfs.csv\", \"../raw_data/2018_wfs.csv\"])\n",
    "\n",
    "# split data set up into three training sets: f9, mmirs, and f5/bino. these sets correspond to the three optical configurations\n",
    "# we use: f/9 and no corrector, f/5 with no corrector (mmirs), and f/5 with spectroscopic corrector (f5/bino).\n",
    "datasets = {}\n",
    "wfs = trimmed.pop('wfs')\n",
    "datasets['f9'] = trimmed[(wfs == 'newf9') | (wfs == 'oldf9')]\n",
    "datasets['mmirs'] = trimmed[wfs == 'mmirs']\n",
    "datasets['f5'] = trimmed[(wfs == 'f5') | (wfs == 'binospec')]\n",
    "\n",
    "# the large range in offsets is messing up the training. so normalize the hexapod coords to their means\n",
    "means = {}\n",
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "train_labels = {}\n",
    "test_labels = {}\n",
    "train_stats = {}\n",
    "normed_train_data = {}\n",
    "normed_test_data = {}\n",
    "for w in datasets:\n",
    "    means[w] = {}\n",
    "    for l in labels:\n",
    "        means[w][l] = datasets[w][l].mean()\n",
    "        datasets[w][l] -= means[w][l]\n",
    "\n",
    "    train_datasets[w] = datasets[w].sample(frac=0.75, random_state=0)\n",
    "    #train_datasets[w] = datasets[w][datasets[w]['mjd'] < 58484.]\n",
    "    test_datasets[w] = datasets[w].drop(train_datasets[w].index)\n",
    "    train_stats[w] = train_datasets[w].describe()\n",
    "    train_stats[w] = train_stats[w].drop(columns=labels)\n",
    "    train_stats[w] = train_stats[w].transpose()\n",
    "    \n",
    "    train_labels[w] = {}\n",
    "    test_labels[w] = {}\n",
    "    for l in labels:\n",
    "        train_labels[w][l] = train_datasets[w].pop(l)\n",
    "        test_labels[w][l] = test_datasets[w].pop(l)\n",
    "        \n",
    "    normed_train_data[w] = norm_dataset(train_datasets[w], train_stats[w])\n",
    "    normed_test_data[w] = norm_dataset(test_datasets[w], train_stats[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "mod_config = {\n",
    "    \"f9\": {\n",
    "        'width': 8,\n",
    "        'nlayers': 2\n",
    "    },\n",
    "    \"f5\": {\n",
    "        'width': 32,\n",
    "        'nlayers': 2\n",
    "    },\n",
    "    'mmirs': {\n",
    "        'width': 32,\n",
    "        'nlayers': 2\n",
    "    }\n",
    "}\n",
    "\n",
    "for w in datasets:\n",
    "    models[w] = {}\n",
    "    for l in labels:\n",
    "        models[w][l] = build_model(\n",
    "            width=mod_config[w]['width'],\n",
    "            shape=len(train_datasets[w].keys()),\n",
    "            nlayers=mod_config[w]['nlayers']\n",
    "        )\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 32)                640       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,729\n",
      "Trainable params: 1,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sel_wfs = 'mmirs'\n",
    "models[sel_wfs]['focus'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training focus model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "......\n",
      "\n",
      "Training tiltx model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..\n",
      "\n",
      "Training tilty model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".\n",
      "\n",
      "Training transx model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...........................................................................................\n",
      "\n",
      "Training transy model....\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..........................................................................................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: \n",
    "            print('')\n",
    "        print('.', end='')\n",
    "\n",
    "EPOCHS = 4000\n",
    "\n",
    "histories = {}\n",
    "\n",
    "for l in labels:\n",
    "    print(f\"Training {l} model....\")\n",
    "    histories[l] = models[sel_wfs][l].fit(\n",
    "        normed_train_data[sel_wfs], train_labels[sel_wfs][l],\n",
    "        epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "        callbacks=[early_stop, PrintDot()]\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in labels:\n",
    "    models[sel_wfs][l].save(f\"../halcoll/data/{sel_wfs}_{l}_train_from_2017_2018_32x32_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa550d8ea4d4e55ba01accbad1208be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48bad43e4154caa987445d4ca2b1fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(histories['focus'], label=\"focus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(wfs, label):\n",
    "    loss, mae, mse = models[wfs][label].evaluate(normed_test_data[wfs], test_labels[wfs][label], verbose=0)\n",
    "\n",
    "    print(\"Testing set Mean Abs Error: {:5.2f} um\".format(mae))\n",
    "    print(\"Testing set RMS: {:5.2f} um\".format(np.sqrt(mse)))\n",
    "\n",
    "    test_predictions = models[wfs][label].predict(normed_test_data[wfs]).flatten()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(test_labels[wfs][label], test_labels[wfs][label] - test_predictions)\n",
    "    plt.xlabel('True Values [um]')\n",
    "    plt.ylabel('Residuals [um]')\n",
    "    minx, maxx = min(test_labels[wfs][label]), max(test_labels[wfs][label])\n",
    "    plt.plot([minx, maxx], [0, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error: 17.05 um\n",
      "Testing set RMS: 32.14 um\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214bcc245c814578a5edb4c7859f1ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results(sel_wfs, 'focus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3040, 711)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = 'focus'\n",
    "test_predictions = models[sel_wfs][lab].predict(normed_test_data['f9']).flatten()\n",
    "diff = test_labels[sel_wfs][lab] - test_predictions\n",
    "diff.idxmax(), diff.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[sel_wfs][lab].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets[sel_wfs].loc[711]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_data = normed_test_data[normed_test_data[sel_wfs] > 0]\n",
    "#chk.index\n",
    "chk_test = test_labels['focus'][chk_data.index] \n",
    "chk_pred = models['focus'].predict(chk_data).flatten()\n",
    "chk_diff = chk_test - chk_pred\n",
    "chk_diff.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = keras.models.load_model(\"/Users/tim/MMT/HALcoll/halcoll/data/tiltx_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(normed_test_data, test_labels['tiltx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = train_dataset['cell_e_series_chamber_ambient_C'] - train_dataset['yankee_temperature']\n",
    "ttt.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error: 116.87 um\n",
      "Testing set RMS: 144.68 um\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f6403bb7d24f2ba7994dd06e0711d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = load_wfs_data([\"../raw_data/2019_wfs.csv\"])\n",
    "w = test_dataset.pop(\"wfs\")\n",
    "test_data = test_dataset[(w == 'newf9') | (w == 'oldf9')]\n",
    "f9_test_labels = {}\n",
    "for l in labels:\n",
    "    test_data[l] -= means['f9'][l]\n",
    "    f9_test_labels[l] = test_data.pop(l)\n",
    "ntest_data = norm_dataset(test_data, train_stats['f9'])\n",
    "\n",
    "loss, mae, mse = models['f9']['focus'].evaluate(ntest_data, f9_test_labels['focus'], verbose=0)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} um\".format(mae))\n",
    "print(\"Testing set RMS: {:5.2f} um\".format(np.sqrt(mse)))\n",
    "\n",
    "test_predictions = models['f9']['focus'].predict(ntest_data).flatten()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(f9_test_labels['focus'], f9_test_labels['focus'] - test_predictions)\n",
    "plt.xlabel('True Values [um]')\n",
    "plt.ylabel('Residuals [um]')\n",
    "minx, maxx = min(f9_test_labels['focus']), max(f9_test_labels['focus'])\n",
    "plt.plot([minx, maxx], [0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error: 159.01 um\n",
      "Testing set RMS: 210.09 um\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678bcde0ad1a425c8db8734b13693d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = load_wfs_data([\"../raw_data/2019_wfs.csv\"])\n",
    "w = test_dataset.pop(\"wfs\")\n",
    "test_data = test_dataset[w == 'mmirs']\n",
    "mmirs_test_labels = {}\n",
    "for l in labels:\n",
    "    test_data[l] -= means['mmirs'][l]\n",
    "    mmirs_test_labels[l] = test_data.pop(l)\n",
    "ntest_data = norm_dataset(test_data, train_stats['mmirs'])\n",
    "\n",
    "loss, mae, mse = models['mmirs']['focus'].evaluate(ntest_data, mmirs_test_labels['focus'], verbose=0)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} um\".format(mae))\n",
    "print(\"Testing set RMS: {:5.2f} um\".format(np.sqrt(mse)))\n",
    "\n",
    "test_predictions = models['mmirs']['focus'].predict(ntest_data).flatten()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(mmirs_test_labels['focus'], mmirs_test_labels['focus'] - test_predictions)\n",
    "plt.xlabel('True Values [um]')\n",
    "plt.ylabel('Residuals [um]')\n",
    "minx, maxx = min(mmirs_test_labels['focus']), max(mmirs_test_labels['focus'])\n",
    "plt.plot([minx, maxx], [0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
